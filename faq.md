---
layout: default
title: FAQ
---

## Frequently Asked Questions

### Which model fits in 8GB RAM?
A smaller model such as `llama3:8b` usually works on a machine with 8GB of RAM.

### How do I update my local models?
Run `ollama pull <model_name>` to download the latest version.

### Ollama command not found
Make sure the Ollama executable is in your `PATH` and restart your terminal after installation.

### Qdrant server failed to start
Verify that Docker is running and ports `6333` and `6334` are free.

### Where can I report bugs?
Please open an issue on the [project's GitHub repository](https://github.com/your/repo/issues).
